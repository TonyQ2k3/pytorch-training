{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TonyQ2k3/pytorch-training/blob/main/nlp/pytorch_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5Pacy1yLgyj"
      },
      "source": [
        "# Pytorch Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfTmWblULgym"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Natural Language Processing (NLP) is a subfield of AI research that focuses on interaction between human and machine. NLP allows computers to understand, interpret and generate human language.\n",
        "\n",
        "Main approaches:\n",
        "1. Rule-based approach: RegEx, Context-free grammar (CFG)\n",
        "2. Probabilistic Modeling and Machine Learning\n",
        "3. Deep Learning"
      ],
      "metadata": {
        "id": "aM6onxVfL7Cn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. CFG\n",
        "Fill semantic slots using pre-configured rules. Has high precision but low recall. Can be inefficient in large systems."
      ],
      "metadata": {
        "id": "J6-JcI34OT5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Machine Learning\n",
        "Train model using data with marked corpus. Perform feature engineering (capitalization, words before/after, etc)."
      ],
      "metadata": {
        "id": "gRNF5NFdO8UV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLP Aspects"
      ],
      "metadata": {
        "id": "AEaurcNhTA7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization\n",
        "+ Splitting text into meaningful units aka tokens. This includes splitting text into sentences, and sentences into words."
      ],
      "metadata": {
        "id": "avdVex72TOUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Pre-processing\n",
        "+ Lower-case words to maintain uniformity\n",
        "+ Stemming aka convert words to their base form (e.g running->run)\n",
        "+ Exclude punctuation marks"
      ],
      "metadata": {
        "id": "Z6LRNrP0T8n2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part-of-speech Tagging\n",
        "+ Assign grammatical categories to words (noun, verb, adj)"
      ],
      "metadata": {
        "id": "pzFmCJJgUCDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Named Entity Recognition\n",
        "+ Identify and classify important entities (names, locations, dates)"
      ],
      "metadata": {
        "id": "Hi64sOz4WVqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependecy Parsing\n",
        "+ Analyze the sentence structure to understand the relationship between words, using a tree-like structure that represents words relationship"
      ],
      "metadata": {
        "id": "0HuT_un6XOcC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PPHan-RCXseq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}